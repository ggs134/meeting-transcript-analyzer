{
    "_id": {
      "$oid": "691cee06d10432b7f947277f"
    },
    "parents": [
      "1DE2SahSPqJAmCJpSBy5voNPQg_vlKeSh"
    ],
    "id": "1lvWZJDodFWQmpw_YYduwVyrWjnILr_L9kJM9zbpFzds",
    "name": "SYB call ‚Äì 2025/11/17 09:22 GMT ‚Äì Notes by Gemini",
    "mimeType": "application/vnd.google-apps.document",
    "webViewLink": "https://docs.google.com/document/d/1lvWZJDodFWQmpw_YYduwVyrWjnILr_L9kJM9zbpFzds/edit?usp=drivesdk",
    "createdTime": "2025-11-17T10:17:47.962Z",
    "modifiedTime": "2025-11-17T11:03:07.670Z",
    "driveId": "0AK6W4i05tbovUk9PVA",
    "size": "24551",
    "content": "Ôªøüìù Notes\r\nNov 17, 2025\r\nSYB call\r\nInvited Aryan Soni Singh Shailendra Manish Kumar\r\nAttachments SYB call \r\nMeeting records Transcript Recording \r\n\r\n\r\nSummary\r\nJamie Judd presented the backend design, which is structured into a synchronizer for maintaining off-chain Merkel trees (graph and score trees) and a forger for submitting batches of transactions from the vouching contract via the `submit batch` transaction. The team agreed on using a dedicated proof server for Zero-Knowledge Proof integration and an Indexer as a Service (like The Graph) for user-facing services and front-end indexing, which Singh Shailendra confirmed they understood. Jamie Judd suggested that Manish Kumar implement the Merkel tree backend (`protocol` package) and Singh Shailendra implement the `syncer` package, with Jeff Chung adapting existing hash code, to begin development on the synchronizer.\r\n\r\n\r\nDetails\r\nNotes Length: Standard\r\n* Vouching Contract and Backend Purpose Jamie Judd began the meeting by presenting the backend design, which primarily aims to manage and update off-chain Merkel trees using data from a vouching contract (00:00:00) (00:04:08). The contract involves two accounts vouching for each other by locking an equal stake, which can lead to cancellation, mutual funding, stealing, or finalization that creates a permanent link (00:02:51). The backend's essential task is updating the contract's graph root and score root via the `submit batch` transaction, using data from an unforged queue (00:04:08) (00:09:10).\r\n* Batch Submission Process The contract process for submitting a batch involves a forger proposing a new graph root, a new score root, the number of new edges (n), and a proof (00:05:23). The contract fetches the next 'n' unforged transactions, packs the edges, generates a storage hash, and combines all the necessary data (including previous roots, new roots, and storage hash) into a single public input to verify the proof (00:06:38). If successful, the contract emits an event and deletes the processed entries from the queue (00:09:10).\r\n* Proposed Backend Structure Jamie Judd proposed dividing the backend into a synchronizer and a forger component. The synchronizer maintains a database storing the two Merkel trees (graph and score trees) and listens to `batch submitted` events to update them, focusing only on the pure off-chain state. The forger runs the sequencer, waits for the unforged queue length to exceed a defined batch size, fetches unforged transactions from the contract, updates its copy of the Merkel trees, generates circuit inputs, and finally calls the `submit batch` function (00:10:20).\r\n* Data Fetching and Batch Size The team discussed the forger's method for fetching unforged transactions. Jamie Judd suggested fetching them directly from the contract, as opposed to saving them from emitted events, because the contract is the ultimate source of information (00:11:30). This is considered acceptable because the update computation is heavy, resulting in small batch sizes, perhaps 10 or 20 transactions (00:12:53).\r\n* User-Facing Backend Services Separate from the core forging process, the backend needs components to facilitate user interaction and viewing of contract state (00:12:53). This includes a service built on top of the synchronizer to provide an API for the score Merkel tree, allowing users to fetch sibling data needed to prove their score against a specific score root. The team discussed options for storing multiple copies or snapshots of the score tree to allow proof against older score roots (00:14:08).\r\n* Indexing and Front End Design Jamie Judd proposed using an Indexer as a Service, such as The Graph, by creating a subgraph for the contract, rather than building a full indexer from scratch. This service would index all contract state for easy viewing (e.g., fetching a user's links) (00:15:22) (00:29:54). A serverless worker, like a Cloudflare worker, would fetch data from the indexer and respond to front-end requests, keeping the front end a simple static page (00:16:39). Singh Shailendra confirmed they understood that the synchronizer would index only the `submit batch` event to update the Merkel tree, while the separate Indexer as a Service would handle the full indexing required for the user front end (00:30:44).\r\n* Synchronizer Implementation Details The synchronizer design was detailed, highlighting that it maintains the Merkel trees and a small `sync state` file to record the last processed block. It will prioritize processing blocks with 12 confirmations to avoid reorgs, using a finality depth of 12 blocks and a chunk size for fetching logs (e.g., 5,000 blocks) (00:19:41) (00:22:14). The synchronizer will load or create the Merkel trees on startup, initializing the graph tree with zero array values if empty (00:21:01).\r\n* Development Division of Labor Jamie Judd suggested that Manish Kumar implement the Merkel tree backend (the `protocol` package in Go) and that Singh Shailendra implement the `syncer` package, which manages the main loop and sync state (00:23:34). Jamie Judd noted that Jeff Chung had already written code for the `hash.go` file (specifically the array hasher) and would adapt it for the backend's needs (00:31:43). Manish Kumar confirmed the Merkel tree library requires both key and value types to be `big int` (00:32:52) (00:36:26).\r\n* Zero-Knowledge Proof Integration Jeff Chung raised concerns about integrating the zero-knowledge proof with the forger (00:38:56). The consensus, informed by how similar projects handle this, was to use a dedicated proof server to generate the ZK proof rather than running the circuit directly on the forger. This is considered the simplest approach and makes sense economically since the proof server is inactive most of the time (00:41:47). The forger configuration will include the proof server's URL and an access key (00:44:14).\r\n* Conclusion on Design and Next Steps The team agreed that the modular and simple design, dividing responsibilities into distinct packages, was good (00:44:14). The immediate next step is to begin development on the synchronizer, focusing on the `syncer` and `protocol` packages .\r\n\r\n\r\nSuggested next steps\r\n* Jamie Judd will add Jeff Chung to the SYB backend repository and add more information about the score tree update to the protocol package.\r\n* Singh Shailendra will work on the syncer.go file, which manages the syncer command, including getting the contract address after deployment.\r\n* Manish Kumar will implement the protocol package, which includes the Merkel tree and applying updates to the Merkel trees.\r\n* Jeff Chung will modify the written hash code and put it in the back end.\r\n* Jeff Chung will take some research on how to integrate the zero knowledge proof with the folder.\r\n\r\n\r\nYou should review Gemini's notes to make sure they're accurate. Get tips and learn how Gemini takes notes\r\nPlease provide feedback about using Gemini to take notes in a short survey.\r\nüìñ Transcript\r\nNov 17, 2025\r\nSYB call - Transcript\r\n00:00:00\r\n \r\nJeff Chung: Hello Jamie.\r\nJamie Judd: Hi Jeff. Hi\r\nJeff Chung: Hello.\r\nJamie Judd: No, thanks.\r\nManish Kumar: Hello Jimmy.\r\nSingh Shailendra: Uh,\r\nJamie Judd: Hey, hey, no problem. Okay. Um, yeah, thanks everyone for for joining. So I'll just I want to go through I mean I over the weekend I'm uh I was working on the back end sort of just trying to specify it very clearly and um kind of in a well structured way and I want to just go through it and just get first get your feedback and then uh yes if there's anything we if you think that needs to to be changed in the design then we can discuss it but I'll just so I'll just share my screen and go through the back end. um back end design that I have in mind and then uh please let me know any feedback. Okay, one second. Okay. Okay. Can you see my screen? Okay.\r\nManish Kumar: He\r\nJeff Chung: Yeah.\r\nJamie Judd: Okay. So I guess first I'll just just quickly have a look at the contract.\r\n \r\n \r\n00:02:51\r\n \r\nJamie Judd: So the contract um is contract is a sort of the vouching contract. So any two accounts will vouch for each other by locking some equal stake. Um so the flow will be A vouches for B and pays some stake S which is a sort of parameter of the contract and then it can either A can cancel the vouch which means their stake will be refunded uh or B can vouch for A and also pay us the same stake A S and then if that happens then we enter this mutually funded uh window from from that moment until plus T uh and then within in the window either A or B can steal which means that we delete this pair so it store it stores a pair AB and we delete the pair the TF gets 2S and there's no permanent link created or it can be closed without stealing um we delete the pair refund both players and no link gets created or after the window ends anyone can call finalize the transaction which makes this link permanent uh refunds each person their stake and appends the link to an unforged queue.\r\n \r\n \r\n00:04:08\r\n \r\nJamie Judd: Okay, so this is the the overall structure. So really the back end is going to be dealing with well the back end has to deal with well the main thing the back end has to deal with is um forging this queue. So the contract will store a graph route and a score route and um the back end has to update those roots uh using the unforged queue. Um there's also sort of a front like a a front end um front end design where uh if a user so if some if people want to view the state of a contract for example A has vouched for V and then B wants to to see okay who who are who is currently vouching for me that I haven't uh revouched then we need some sort of UX for that and also So um things like how much time is left in the window and stuff like that but that's that's m that is mostly uh to do with the UX because the information is all in the contract and we just are we are just um we can just build a convenient uh sort of indexer or convenient front end to view that information in the contract.\r\n \r\n \r\n00:05:23\r\n \r\nJamie Judd: The only the the only thing that the back end is sort of essential for is uh this uh sort of this uh updating the the graph route and score routt because the back end actually holds um an off-chain state that the contract doesn't know about i.e. the the two Merkel trees. Um yeah. So then anyway, this is if if uh if if you need to reference the contract to find out something, then here's the um here's the implementation. Um yeah, so it has it has events for um the different kind of user actions. But then the main thing that the back end will be doing is this uh calling this submit batch or dealing with this submit batch uh kind of transaction. So the a forger will submit a batch by um propose. So uh it's giving a new graph root. This is graph root, new score root. Um n which will be the number of uh new edges it's going to forge. And then a proof. And then the contract will fetch the next.\r\n \r\n \r\n00:06:38\r\n \r\nJamie Judd: So it has a sort of last forged ID. This is the last forged uh transaction or edge that has been added. And the contract will get um the next n in the unforged queue. It will check the next n unforged transactions and it will um first it will so so then it run it runs this build edges and storage hash. So first what it does is it packs the edges into um so it say n edges. So let's say n is um 20. So it's a batch of 20 edges. So it packs the the edges are just an edge is just given by two uh u 32s. So it's a u 64 one edge one edge is given by un 64. So it's just the id of it's the it's the two ids of the of the um the the people the the nodes that are vouching ordered like from smallest to biggest. I just want to just Yeah. So here uh oh yeah no sorry not ordered smallest to biggest biggest but ordered the um smallest to biggest based on the on the address but anyway it's it's a UN 64 each edge.\r\n \r\n \r\n00:07:55\r\n \r\nJamie Judd: So it takes the last the next n edges from the unforged q. Um so it takes n u64s and packs them into a like into a bite array and then the edges packed and then it will run kekak hash on that bite array to uh to output the the storage hash. Um okay and then the next thing is it does is it wants to compute it wants to provide a single public input for the circuit. So uh it just to do this I mean it could it could give all of these as public inputs into the circuit but it would be more uh the the verifying cost will be lower if it's just a single public input. So what it does it just it just uses keac to um combine all of these. So basically all the the things that have been claimed about um sort of the the la previous previous previous roots new roots and storage hash. Um this is the the kind of the edge the edge data the new the new transaction data uh into a public inputs and then verifies public verifies the proof for those public inputs.\r\n \r\n \r\n00:09:10\r\n \r\nJamie Judd: That's the batch uh transaction. So we need to create a we need to create a backend that is able to call this uh transaction. That's sort of the main purpose of the back end to be able to call this submit batch transaction. Um yeah and then at the end it deletes emits an event and deletes the the processed entries from the queue. This is the edge packing. So packs n edges like this and then this is just the taking the hash of the the edge packing. Okay. So that's just the the contract. Um yeah. So basically yeah if we want to try and create some back end that is able to call this function submit batch. So this is the Yeah. Is there a question? Sorry. Yes. Oh, sorry. No, no question. Just Okay.\r\nSingh Shailendra: It's all good.\r\nJamie Judd: Okay. Um Okay. Yeah. So that was So the back end. So for the back end, I'm um thinking of dividing it up like this.\r\n \r\n \r\n00:10:20\r\n \r\nJamie Judd: So let me know your thoughts on it. So we would have a the first thing we'd have is a synchronizer. Sync the synchronizer just maintains the database which stores the two Merkel trees like the graph tree and the score tree and has a routine which just listens to the batch submitted event and updates the Merkel trees each time it gets a new batch submitted event. So it's it's all it's doing is just storing the offchain Merkel trees and syncing every time. It's not trying to store all the other tables of um sort of vouchers and kind of intermediate state. It's just trying to store the the pure off-chain state, not the state that the contract already knows about. And then there will be a forger which will will run the sequencer. So it needs to be aware of the the current offchain state and then it uses this um so it uses the database that's maintained by the sequencer to forge new batches. So it just waits until the the unforged q length is greater than forger batch size.\r\n \r\n \r\n00:11:30\r\n \r\nJamie Judd: So this is some size they choose how often they want to forge and then it just fetches the next forge batch size unforged transactions from the contract and makes a copy of the latest version of the Merkel trees and applies the unforged transactions to update its copy of the Merkel trees and then uses its updated copy of the Merkel trees to generate the circuit inputs like basically the sibling data and some other data. uh which is this creates the ZK input for the circuit. Um so then it runs the circuit to create a proof and then it calls submit batch in the contract. Um I just wrote this note. So instead of fetching the unforged transactions so here we actually fetch them from the contract. We could catch them as they are emitted like every time there's a new transaction added to the unforged queue then we could catch it and save them in the back end but I think it it's not necessary and it sort of um makes another thing we have to do and we'd have to change our sequencer to also listen to the linked events and um we we'd have to make our forger have a sort of an SQL table as well to store them but I think and and I I mean I think that the the contract is the ultimate um source of the information.\r\n \r\n \r\n00:12:53\r\n \r\nJamie Judd: So I think it's fine just to fetch the fetch the unforged transactions directly from the contract especially if our batch is not too big. It won't be the batches won't be very big because it's quite uh the comput the update computation is heavy. So the batches will be smallish like maybe 10 or 20. Um okay and then so these these two parts are the main parts for the for the um calling the submit batch um function. So we need synchronizer and then the forger which runs as in addition to the synchronizer and then and then sort of the other parts of the back end are separate. they are to do with uh basically they're to do with the front end how we can view the the contract state or how we can make our users be able to interact with the contract. Um so what I was thinking was um okay so one so one thing that the users would need would be uh to be able to fetch their fetch the score fetch the siblings for the score tree um because if they want to prove their score for a particular score route like I want to prove this is the score route that the contract knows about.\r\n \r\n \r\n00:14:08\r\n \r\nJamie Judd: I want to prove that uh at that batch uh my score was something then they need the siblings for that for their leaf in that score tree um which doesn't this is not available in the contract so we need to provide this somehow so we can provide this on top of the synchronizer package so you just I mean one way would be they run the synchronizer package themsel and then they'd have it but I mean we don't want to expect people to do that so we could run we could make some service that runs the synchronizer package package and then provides an API for the score Merkel tree for users to fetch the siblings. Um, and then there's some add some u variations. We could uh we could keep multiple copies of the score tree in the database or take snapshots every 10 batches. So we can provide roots um at for for many or or any of the recent score roots not just a single score route because as written the synchronizer just kind of keeps the most upto-date Merkel tree but if a user wanted to prove their score for an old version of the score tree then we might need to keep snapshots of old um of old Merkel trees.\r\n \r\n \r\n00:15:22\r\n \r\nJamie Judd: Um and then the other note is instead of having an API uh we could just um write the score tree because it's a very it's a very sort of static thing that um is being is being uh read. So we so after we uh do it we could just write the score tree to some cheap storage like Amazon S3 and then update this periodically or every batch or less often and the users can just fetch that fetch their siblings from that like via our front end. So and then the other part that we need is a we need an indexer for the contract. So for all the sort of the contract state that the contract knows about we need to that uh to be viewed in an easy way. For example, if a user wants to say I want to fetch all all my links, then they won't be able to do that directly in the contract. They need uh some indexer to to help them do that. So um this is something I was thinking I mean initially I was thinking we just we could just build this indexer um like having a table for all the different types of uh kind of pairs and all the all the different types of things that can happen in the contract.\r\n \r\n \r\n00:16:39\r\n \r\nJamie Judd: Um but I'm thinking now that it could be simpler if we just use this in use an indexer as a service. So we just um like something like the graph where you just create our own subgraph for our contract and it just it does the indexing for us and um yeah I I mean I don't know much about this but if if I'll hear what you guys say about it but um then our front end wouldn't wouldn't talk to the graph directly. Instead, we'd have some serverless worker like a Cloudflare worker which holds the the GraphQL key and responds to requests from our front end by fetching data from the graph. And then the front end would just be a simple static page that our domain points to. And it so it fetches data from the graph via our subless worker. And then it the user can use this page to send transactions to the contract. And if they want to do a prove score transaction then they will need to fetch the sibling data uh from the DB in uh from the from the database from our from this one really the uh number three.\r\n \r\n \r\n00:17:54\r\n \r\nJamie Judd: Um yeah. Okay. And so yeah, so this is the design I'm thinking of. Any uh comments or suggestions about this?\r\nJeff Chung: No from my side.\r\nJamie Judd: Okay. Um okay.\r\nManish Kumar: Yeah, I think it's looking good as of now.\r\nJamie Judd: Um so yeah so I mean the main difference was before before is so but we we basically we still need some sort of in indexer for this synchronizer but it will be much much simpler because we just need\r\nManish Kumar: Yeah.\r\nJamie Judd: to we just need a single um we just need to catch a single event the batch submitted event um and we just need to to update the Merkel trees. don't need to deal with um we don't need to have all of the tables in our back end and we don't need to be catching every event in our back end. Um so yeah so that's the main thing. Okay. So then I think yeah so the first part would be to to just make this synchronizer which is just something that maintains the database and can catch the batch submitted events and yeah so the so this simp this synchronizer will be very will be easy because this batch submitted event there was just a single event we need to catch and also it doesn't need to be uh it doesn't we can have a delay on it.\r\n \r\n \r\n00:19:41\r\n \r\nJamie Judd: So like it's not like uh it's not for the front end. So it's not some we don't need to um catch the events as soon as soon as they're emitted. We can we can wait say 12 for 12 finalizations on this event uh to make sure we don't so then we don't even need to do any reorg. We can just um assume that it's finalized because there's so this is for the forger. There's no, it's not really an urgent thing. It just needs to eventually uh catch up. Um so yeah, so the synchronizer would would look something like this. So we um we have our yeah, we have our start block and our finality. So we we pick some finality depth and a chunk size number of blocks and then um the the config for the Merkel trees and then our the persistent state in the synchronizer will just be the Merkel trees uh which we'll use this using this and then we just need to store one um small file called the sync state which is just going to record the last processed block.\r\n \r\n \r\n00:21:01\r\n \r\nJamie Judd: Um, so the last block that we processed. So we we Yeah. So this is the only part of the only kind of part of the the database that we need that's not in the Merkel tree. But uh I think it's not worth it to to make a kind of a whole SQL table just for this. I mean, we because we're not even using I I mean, I don't want to put it into this um package because um I don't want to mess with the uh the Merkel tree package by adding in some extra things. So, I think it's easiest just to keep it like this. Uh so then on startup the synchronizer would um yeah load or create the score tree load or create the graph tree then it will run if the graph graph tree is empty then it will run some initialization process for the graph tree where it inserts a special hash zero array value at at each leaf. Um yeah. So basically saying that each leaf has an array of zeros as its neighbors and then it will fetch the the sync state to get our last processed block.\r\n \r\n \r\n00:22:14\r\n \r\nJamie Judd: Otherwise set it just to start block minus one. And then the main loop would be to get the the current block number and then our target would be minus 12. So we'll just look for things that have been have 12 confirmations and then um so we need to catch up. So we would just check if we need to catch up and then if we do we would so a chunk size of say 5,000 and we would um get the logs for our contract just for this um batch submitted event from our starting point to that plus chunk size um and sort them and then apply the logs to the Merkel trees and then update our sync date and then just progress. Um, so I haven't written out the details for these ones yet, but this is Yeah. So, this is what I think the design should be. And then this is a a draft of the of the structure of it. So, be something like this. Like we'd have this would be the Merkel tree packages.\r\n \r\n \r\n00:23:34\r\n \r\nJamie Judd: Um then we would have so this we'd have some package called protocol which will um manage the Merkel trees and manage the sort of the up the updating of the Merkel trees. Um so it yeah so this does does it this um does initialization of Merkel trees and updating of Merkel trees after it receives batch data and then another package called syncer which does the the the loop and um yeah stores the sync state. And then we have another package called forger which which does what before which is basically um checking when it's time to forge and then forging getting building the forge building the submit batch transaction and then we so we could run so in this package we can run our syncer loop um which just so the syncer loop will just um up read the contract and update our Merkel tree and then we could also run our forger loop with some configuration to decide how often to forge and yeah so I mean I I've sketched out different the different files here as well so um I'm thinking so um to divide it up so any any oh any questions about so far.\r\n \r\n \r\n00:25:20\r\n \r\nSingh Shailendra: Air to Wford.\r\nJamie Judd: Okay.\r\nManish Kumar: All right. Looking over there.\r\nJamie Judd: Okay. So, um I'm thinking before I was uh Yeah. So, I saying manish you could um implement the the Merkel tree in Go the Merkel tree back end in Go and Shendra you could um implement the syninker. So if we divide it like this then like they'll be divided into two packages. So can kind of keep them independent a little bit. I mean they they the sinker will actually use this package but it keeps them a bit independent. At least the sinkers all the sinker the sinker logic is going to be separated.\r\nManish Kumar: Yeah, we will make them modular.\r\nSingh Shailendra: Yeah, right.\r\nJamie Judd: Yeah.\r\nManish Kumar: Yeah.\r\nJamie Judd: Um and then the forger we can we can think about after. Um Yeah.\r\nManish Kumar: Right.\r\nJamie Judd: And so yeah, so I think um if so if Shendra if you start working on this the sinker go file um which does the well first I mean I guess first we need to um just to get the\r\n \r\n \r\n00:26:25\r\n \r\nSingh Shailendra: Okay.\r\nJamie Judd: deploy the contract and um yeah get an address for it and things but if you start working on this um and manage you work on this um the protocol package which is basically the Merkel tree and applying the um kind of updates to Merkel trees. Um we could we can try and yeah try and do a test at some point. Oh and also I mean this this is also part of the the syncer this uh syncer command but it's quite simple.\r\nManish Kumar: Right.\r\nJamie Judd: It's just a a normal kind of the normal Yeah, it's just create new syner give the config and then create the new sinker and run the syncer\r\nSingh Shailendra: Yeah, it will just Yeah, it will just call the center. Uh so like uh just to be sure do you mean that our whole indexes should only be just one file syncer.go because I think we discussed on last call that this will be a full-fledged indexes. So I think it may require more files than just one file in the sinker folder.\r\nJamie Judd: Um so on on the last call the last call we were discussing kind of a full indexer.\r\n \r\n \r\n00:27:38\r\n \r\nJamie Judd: So oh yeah so so this is just so this um this file structure is just for um part one and part two. So this is just for um um like for the two parts you know the so here I have the so here we have the the main part so there's the synchronizer part and the forger part then\r\nSingh Shailendra: Uh-huh.\r\nJamie Judd: there's the the other part is the the full indexer but for that I'm but for that I think that well what do you think I I think we uh should use this indexer as a service to make it\r\nSingh Shailendra: Good.\r\nJamie Judd: a lot easier. And um um yeah, what what do you think about it?\r\nSingh Shailendra: Uh no no I am confused a bit in this like uh yeah we can use the indexer as a service uh then our indexer will index all the events which we need uh then we can somehow call that indexer and the forger do we need a separate syner for that like uh segret will do synch will do the same thing as indexer.\r\n \r\n \r\n00:28:49\r\n \r\nSingh Shailendra: So we will be doing the same thing in a separate sync here if that's what you need.\r\nJamie Judd: No, no, no. Sinker. So, this file syncer uh I'll just I'll show you this file. So, the syncer is actually um only doing the uh submit batch event.\r\nSingh Shailendra: Okay. Only indexing one event.\r\nJamie Judd: Yeah. So, so at the moment, so I'm I'm just thinking about at the moment I'm only thinking about this.\r\nSingh Shailendra: Okay.\r\nJamie Judd: Uh, so maybe I should even get rid of this forger. Well, I'll just leave it just for the moment. But um, but this is so this this whole structure is just for is just for this synchronizer and forger.\r\nSingh Shailendra: It's okay. I understand.\r\nJamie Judd: I haven't I haven't written ending for these three yet. So, so this um this syncer I'll just I'll just go down to the syncer and have a look the syncer here.\r\nSingh Shailendra: Okay.\r\nJamie Judd: So, it doesn't have any SQL. It doesn't have any SQL tables.\r\n \r\n \r\n00:29:54\r\n \r\nJamie Judd: It doesn't write to any SQL tables at all. This syncer it just it just um so it has a config and the finality depth and it just listens to a single event which is batch submitted.\r\nSingh Shailendra: Okay.\r\nJamie Judd: So it it the only job of this synchronizer is to update the Merkel trees.\r\nSingh Shailendra: Okay. So, okay, I got it. So, earlier I was thinking that uh we will use index set to update the ML tree but you want to keep it separate and a syncer and this we will use the syncer to upgrade the tree.\r\nJamie Judd: Yeah. Because Yeah. So the so this uh Yeah. So this um indexer as a service basically is this is for the front end. this for the users to like things find things like who are all the link who are all my links that I or all my vouchers and things like that.\r\nSingh Shailendra: Yeah.\r\nJamie Judd: Um it's information that's available in the contract but we can't we can't get it from the contract easily.\r\nSingh Shailendra: Yeah.\r\n \r\n \r\n00:30:44\r\n \r\nSingh Shailendra: Got it. Yes, I understand.\r\nJamie Judd: Yeah.\r\nSingh Shailendra: Understand?\r\nJamie Judd: So this and this sinker this sinker is it doesn't uh it doesn't it doesn't expose any kind of API really. It's just completely um part of the forger. So it's just a a package run by some by someone to so these basically these two first parts are just in order to be able to call the submit batch contract. Um okay so yeah so this is it is not a full indexer this synchronizer. It's it's just Yeah.\r\nSingh Shailendra: Yeah. Yeah. Yeah. I got it. I got it. We need synchronizer just for uh to update the Merkel tree. Uh it will just index one one event a batch event and uh the indexer will be used for a full front end for user experience. So it needs to be fast and it needs to index most of the events.\r\nJamie Judd: Yeah. Exactly.\r\nSingh Shailendra: So that's why we'll keep it separate.\r\nJamie Judd: Yeah.\r\n \r\n \r\n00:31:43\r\n \r\nJamie Judd: So, yeah.\r\nSingh Shailendra: Okay.\r\nJamie Judd: So, these three the three, four and five are basically like the front end for the users and then one and two are the kind of the the back end which is going to be calling the um uh calling the the submit match function. Okay. Um, yeah. Okay. So, Oh, and then just um Yeah.\r\nSingh Shailendra: Okay, got it.\r\nJamie Judd: And then Oh, yeah. One thing just Jeff I think for this so maybe for this hash.go or for some of the Yeah, for maybe hash.go I think um you already have written some code for that I think.\r\nJeff Chung: Yes, I did.\r\nJamie Judd: Mhm. Okay. So yeah, basically the hash row is just uh it it kind of it does this function this array hasher. So given an array, it will implement like it will sort of chunk the array and implement Poseidon 16 over the chunks to output some to output some uh yeah some hash.\r\nJeff Chung: Yeah.\r\nJamie Judd: Okay. Yeah.\r\nJeff Chung: Yeah.\r\n \r\n \r\n00:32:52\r\n \r\nJamie Judd: So you you already have this written.\r\nJeff Chung: Okay. Yeah, but the I think the the input and output is quite different. So I could kind of modify and put it there in the back end.\r\nJamie Judd: Yeah. Okay. But I mean I'm not this is this is just a guess. I'm not sure if this is the correct uh style or I mean um it depends what what the Merkel tree wants for its value.\r\nJeff Chung: Yeah.\r\nJamie Judd: So I I think that the Merkel sorry the the yeah the Merkel tree package wants big int as its value that you like when you want to add a key value into the Merkel tree you need to give\r\nJeff Chung: Okay.\r\nJamie Judd: it as a big int. So we so I guess uh something like so I so yeah something like this but we can\r\nManish Kumar: Yeah, right. The return value should be begin. Correct.\r\nJeff Chung: Okay. Okay.\r\nManish Kumar: I think uh I have already seen the ZF code, the hasher and I think he does support both types.\r\n \r\n \r\n00:33:44\r\n \r\nManish Kumar: Am I right Zev? Like uh the begin and the normal ones as well. Uh Ze, are you there?\r\nJeff Chung: Yeah, I'm not sure. Let me see.\r\nManish Kumar: I think it uh I have seen your code. I think it does support both types uh the begin and the normal integer type as well.\r\nJeff Chung: Okay. Oh, yeah.\r\nManish Kumar: Yeah, it does that.\r\nJeff Chung: Yeah. Yeah, I did. I did. I did speak in\r\nManish Kumar: Yeah.\r\nJamie Judd: Okay. And yeah. Um. Okay. So, yeah. And then the rest of this uh protocol package is mainly it's made I mean actually I need to um add some more information about the sort of the score tree update but at least for the applying applying updates to the uh graph tree it can be done it can be done using the the this neighbor hasher neighbor array hasher Um so yeah this is\r\nManish Kumar: All right.\r\nJamie Judd: okay.\r\nJeff Chung: Oh, by the way, so uh the score tree is just using the Poseidon uh I think it's three for for the I mean the Poseidon hasher is the same as the original one, right?\r\n \r\n \r\n00:35:20\r\n \r\nJeff Chung: We just send in is it a sparse mro tree or just a mro tree?\r\nJamie Judd: Hey sparse Merkel tree. So we'll use the the back end will use this go Merkel tree SQL package. Um which means you don't need to you don't need to define the you don't need to use any hash algorithm.\r\nJeff Chung: Okay.\r\nJamie Judd: I mean maybe you need to just say I'm using Poseidon but after that it will just it will do everything. So you just give it a a key value. I think both are big int maybe and just say like you just you add you say add key key value to your tree and then the package will um use Poseidon tree with the key the value and some tag one to create the node hash and then it will insert it into the into its Merkel tree.\r\nJeff Chung: Okay.\r\nJamie Judd: But we don't need to do that here.\r\nManish Kumar: Yeah, right.\r\nJeff Chung: Okay.\r\nManish Kumar: I think last weekend um I did try it uh try the library the and it uh the value type must be begin, right?\r\n \r\n \r\n00:36:26\r\n \r\nManish Kumar: And it does uh it's only support the key value uh type of configurations.\r\nJamie Judd: Yeah.\r\nJeff Chung: Okay, I see you.\r\nManish Kumar: Yeah.\r\nJamie Judd: But yeah, but for the but for the graph tree, our value will be it will be a it will be a sort of it will already be a big int that's outputed by our neighbor hasher algorithm.\r\nManish Kumar: Yeah, but I think uh their key must al must also be uh in big form.\r\nJamie Judd: Okay. Okay.\r\nManish Kumar: Yeah, I did try it. I I think I did try to pass the random integer. I think it's uh U64 but it didn't take it. It uh like uh the error was the value must be big.\r\nJamie Judd: Okay. Even for the key.\r\nManish Kumar: Yeah.\r\nJamie Judd: Yeah. Yeah. Yeah.\r\nManish Kumar: Yeah.\r\nJamie Judd: Actually, that's true.\r\nManish Kumar: Right.\r\nJamie Judd: Yeah. So we would just need to um we just need to convert our our index our node index into a big in yeah because actually I mean the sparse tree it's the way they've designed it\r\n \r\n \r\n00:37:17\r\n \r\nManish Kumar: Yeah. I think that's not a big deal. We can do that. Right. Cool.\r\nJamie Judd: they they normally expect the key to be a hash of something. Um, so yeah, that's why they're expecting big int for the key, but actually we're just using the index like the the number of the index as the key.\r\nManish Kumar: Right. Right.\r\nJamie Judd: Okay. Um, so yeah, so we can uh yeah, we can work in this. I I I don't know if I added you to this uh repository, the the SYB back end. Jeff, have I added you to this?\r\nJeff Chung: I think not yet. Yeah.\r\nJamie Judd: I'll add you to this as well. Um I mean, yeah.\r\nJeff Chung: Thank you.\r\nJamie Judd: Um yeah, I think that's all really. I mean I don't know what what for the sort of the first uh yeah the first I think I mean excluding forger this is sort of a um a complete setup that we can run and test. We might need yeah for testing it we might need um I mean we can yeah we can we can create sort of dummy submit batch transactions in the contract to test it because we're not actually we're not um yeah I think\r\n \r\n \r\n00:38:56\r\n \r\nJeff Chung: Yeah. And I have one question also. So So because we don't we don't need the forger now. So Oh yeah. I I mean because forger is related to the circuit. I was worried about the how to integrate the zero notch proof with folder.\r\nJamie Judd: Okay. Um, so I think that uh I think that maybe we can include the circuits in in this backend folder as well. Um, I don't Is this what you mean? I don't I'm not sure. Is this what you mean? Like put another package called circuit some inside here or is that not what you mean?\r\nJeff Chung: Um, I think I need to think about it, but I I don't think we should include it inside here. Yeah.\r\nJamie Judd: Okay. So, so when we run this forger main.go go this command um will so it will it will it will start two um so I guess actually if you want to run a forger we will we will start the\r\nJeff Chung: Yeah.\r\nJamie Judd: syncer command and then we'll also run a forger routine as well on top and the syncer command will just keep updating our merkel trees and then the forger routine will um read the merkel trees and write to contract\r\n \r\n \r\n00:40:27\r\n \r\nJeff Chung: Okay.\r\nJamie Judd: um and I don't So yeah, so I mean I guess we need to at some point the forger needs to use the circuit to generate a proof before it sends it to the correct.\r\nJeff Chung: Yeah.\r\nJamie Judd: So I don't know where or I don't know what's the kind of clean way of doing that whether we should have the circuits inside this repository or I don't uh import them something like that. How do how would you suggest Yeah.\r\nJeff Chung: I think I need to take some research on that. How does the Heras is that Hermes the the project we take reference before how does they do cuz they also write the circuit in circum All right.\r\nJamie Judd: Yeah. I'll just have a quick check. I think it's Yeah, that's right. So it will be it's very very huge and complicated this project. It's quite hard to find things.\r\nJeff Chung: Oh.\r\nJamie Judd: I'll just try and have a look. So where where would we find it? We'd find it in Shelender.\r\n \r\n \r\n00:41:47\r\n \r\nJamie Judd: You've had a look at this. Do you know where I could look? In here, maybe. I think I think it it kind of does it some of sort of proof server. Yeah, proof server, doesn't it?\r\nSingh Shailendra: I don't think\r\nJeff Chung: Oh, okay.\r\nJamie Judd: Um I I mean there might be a simpler way to do it than than the way they they do it.\r\nJeff Chung: Yeah, I think it's better to have a sort of like a proof server to generate the proof instead of just run the circuit directly on folder.\r\nJamie Judd: Okay. Okay. So, you think doing it the same way as them is is a good way?\r\nJeff Chung: Yeah, I think it's the simplest way and if there's any problem we could like switch it into I think for the first implementation we could do the the proof server.\r\nJamie Judd: proof server. Okay.\r\nJeff Chung: Yeah.\r\nJamie Judd: Um Okay. Yeah, then that's fine.\r\nJeff Chung: Because if we want to write the circuit in gark that would be quite time consuming because we I don't know how grimox works.\r\n \r\n \r\n00:43:19\r\n \r\nJeff Chung: Yeah.\r\nJamie Judd: Yeah. Yeah. No, I I think Okay. So, you mean if if we wanted to include it in this uh like with our other files, then we should we should have it in Ganach. But if then we need to use a P server.\r\nJeff Chung: Yeah. Yeah.\r\nJamie Judd: Okay. That's fine. Yeah.\r\nJeff Chung: Yeah.\r\nJamie Judd: Okay. Um so so a proof server so the way a proof server works is we just uh kind of deploy some server with our circuit uh that receives um a request from the forger and then gives a response of\r\nJeff Chung: Yeah.\r\nJamie Judd: a proof.\r\nJeff Chung: Yeah.\r\nJamie Judd: Okay. Yeah. Okay. Actually that makes sense because the proof server is going to be inactive most of the time.\r\nJeff Chung: Yeah. Yeah.\r\nJamie Judd: We don't want to like use and it's expensive and inactive.\r\nJeff Chung: this.\r\nJamie Judd: So we don't want to kind of use all its uh energy.\r\nJeff Chung: Yes. Yes.\r\n \r\n \r\n00:44:14\r\n \r\nJamie Judd: Yeah. Okay. So poop server is a good way doing it. Um and then I mean so then we have to give some kind of access key to the to the forger here. That'll be part of the forger config would be the the URL and the access key for the proof server.\r\nJeff Chung: Yes, probably.\r\nJamie Judd: Okay. Yeah. Okay. That sounds good. Yeah. So then this this package is fine like it is. We don't need to add anything. We don't need to add any circuits in this.\r\nJeff Chung: Yeah, I think so.\r\nJamie Judd: Okay. Um yeah, I think that's the main thing then. And if anyone has any other questions, I mean if you have any uh if you think there's anything wrong with this uh overall design, then let me know. I mean, basically my aim is to to try and make it sort of modular and simple and um yeah, so I sort of each part is just kind of doing a reasonably simple task. Um yeah.\r\nSingh Shailendra: Yeah.\r\nJamie Judd: Okay.\r\nManish Kumar: This initially is looking good.\r\nJamie Judd: Okay. So, yeah. So, we'll just start on this part one, the synchronizer, which is the uh yeah, the protocol. So, the the the syncer package and the protocol package.\r\nSingh Shailendra: syn. Yeah.\r\nJamie Judd: Yeah. And we can try and get them working.\r\nSingh Shailendra: Okay.\r\nJamie Judd: Okay. Okay. Thanks, guys.\r\nSingh Shailendra: Okay. Thank you guys.\r\nJamie Judd: All right. Byebye.\r\n \r\n \r\nTranscription ended after 00:46:07\r\n\r\n\r\nThis editable transcript was computer generated and might contain errors. People can also change the text after it was created.",
    "created_by": "Jamie"
  }