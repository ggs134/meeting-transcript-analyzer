"""
ì¼ê°„ ì—…ë¬´ ë³´ê³ ì„œ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
íŠ¹ì • ë‚ ì§œì˜ íšŒì˜ë¡ë“¤ì„ ë¶„ì„í•˜ì—¬ ê° íŒ€ì›ì˜ ì¼ê°„ ì—…ë¬´ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥í•˜ê²Œ í•¨
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from meeting_performance_analyzer import MeetingPerformanceAnalyzer
from utils.run_analysis import get_analyzer

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ìƒìœ„ ë””ë ‰í† ë¦¬)
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
load_dotenv(dotenv_path=env_path)


def get_target_date(date_str: str = None):
    """
    ë¶„ì„ ëŒ€ìƒ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        date_str: ë‚ ì§œ ë¬¸ìì—´ (YYYY-MM-DD í˜•ì‹). Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
        
    Returns:
        datetime ê°ì²´
    """
    if date_str:
        try:
            return datetime.strptime(date_str, '%Y-%m-%d')
        except ValueError:
            print(f"âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date_str}. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
    else:
        return datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)


def fetch_meetings_for_date(analyzer: MeetingPerformanceAnalyzer, target_date: datetime):
    """
    íŠ¹ì • ë‚ ì§œì˜ íšŒì˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        analyzer: MeetingPerformanceAnalyzer ì¸ìŠ¤í„´ìŠ¤
        target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
        
    Returns:
        í•´ë‹¹ ë‚ ì§œì˜ íšŒì˜ ë¦¬ìŠ¤íŠ¸
    
    Note:
        - `date` í•„ë“œê°€ ìˆëŠ” ê²½ìš°: date í•„ë“œë¡œ í•„í„°ë§
        - `createdTime` í•„ë“œë§Œ ìˆëŠ” ê²½ìš° (Google Drive ìŠ¤í‚¤ë§ˆ): 
          fetch_meeting_recordsê°€ ìë™ìœ¼ë¡œ createdTime í•„ë“œì—ë„ ë™ì¼í•œ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
          createdTimeì€ ISO 8601 ë¬¸ìì—´ í˜•ì‹ì´ì§€ë§Œ, ISO í˜•ì‹ì€ ì‚¬ì „ì‹ ì •ë ¬ì´ ì‹œê°„ ìˆœì„œì™€ ì¼ì¹˜í•˜ë¯€ë¡œ
          ë¬¸ìì—´ ë¹„êµë¡œë„ ì •í™•í•˜ê²Œ ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """
    # í•´ë‹¹ ë‚ ì§œì˜ ì‹œì‘ê³¼ ë ì‹œê°„
    start_datetime = target_date.replace(hour=0, minute=0, second=0, microsecond=0)
    end_datetime = target_date.replace(hour=23, minute=59, second=59, microsecond=999999)
    
    # ë‚ ì§œ í•„í„° ì¿¼ë¦¬
    # fetch_meeting_recordsê°€ ìë™ìœ¼ë¡œ 'date' í•„í„°ë¥¼ 'createdTime' í•„ë“œì—ë„ ì ìš©í•©ë‹ˆë‹¤.
    # ë”°ë¼ì„œ Google Drive ìŠ¤í‚¤ë§ˆ(createdTime ì‚¬ìš©)ì™€ ì¼ë°˜ ìŠ¤í‚¤ë§ˆ(date ì‚¬ìš©) ëª¨ë‘ ì§€ì›ë©ë‹ˆë‹¤.
    query = {
        "date": {
            "$gte": start_datetime,
            "$lte": end_datetime
        }
    }
    
    meetings = analyzer.fetch_meeting_records(query)
    return meetings


def generate_daily_report(analyzer: MeetingPerformanceAnalyzer, meetings: list, target_date: datetime):
    """
    ì¼ê°„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        analyzer: MeetingPerformanceAnalyzer ì¸ìŠ¤í„´ìŠ¤
        meetings: ë¶„ì„í•  íšŒì˜ ë¦¬ìŠ¤íŠ¸
        target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
        
    Returns:
        ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ê° ê²°ê³¼ì— ì›ë³¸ ë¯¸íŒ… ì •ë³´ ì¶”ê°€ë¨)
    """
    if not meetings:
        print(f"âš ï¸  {target_date.strftime('%Y-%m-%d')} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” íšŒì˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    print(f"\nğŸ“Š {target_date.strftime('%Y-%m-%d')} ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    print(f"   ë¶„ì„ ëŒ€ìƒ íšŒì˜: {len(meetings)}ê°œ")
    
    # ì›ë³¸ ë¯¸íŒ… ë°ì´í„° ìˆ˜ì§‘ (ê° íšŒì˜ì˜ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥)
    target_meetings_info = []
    for meeting in meetings:
        # _id í•„ë“œ ì‚¬ìš© (MongoDB ObjectId)
        meeting_id = meeting.get('_id', '')
        if isinstance(meeting_id, dict):
            # {"$oid": "..."} í˜•ì‹
            meeting_id = str(meeting_id.get('$oid', ''))
        elif meeting_id:
            # ObjectId ê°ì²´ì´ê±°ë‚˜ ë¬¸ìì—´
            meeting_id = str(meeting_id)
        else:
            # _idê°€ ì—†ìœ¼ë©´ id í•„ë“œ ì‚¬ìš© (fallback)
            meeting_id = meeting.get('id', '')
        
        target_meetings_info.append({
            'meeting_id': meeting_id,
            'meeting_title': meeting.get('title', meeting.get('name', 'N/A')),
            'created_time': meeting.get('createdTime', meeting.get('date', 'N/A'))
        })
    
    # daily_report í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„
    # daily_reportëŠ” ì—¬ëŸ¬ íšŒì˜ë¥¼ í•œë²ˆì— ë¶„ì„í•´ì•¼ í•˜ë¯€ë¡œ analyze_aggregated_meetings ì‚¬ìš©
    aggregated_result = analyzer.analyze_aggregated_meetings(
        meetings,
        template_name="daily_report",
        custom_instructions=f"ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ: {target_date.strftime('%Y-%m-%d')}",
        version="latest"  # ìµœì‹  ë²„ì „ ì‚¬ìš© (JSON í˜•ì‹)
    )
    
    # analyze_aggregated_meetingsëŠ” ë‹¨ì¼ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if aggregated_result:
        analyzed_results = [aggregated_result]
    else:
        analyzed_results = []
    
    # ê° ë¶„ì„ ê²°ê³¼ì— ëª¨ë“  ì›ë³¸ ë¯¸íŒ… ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ê°€
    for result in analyzed_results:
        result['target_meetings'] = target_meetings_info
        result['target_date'] = target_date.strftime('%Y-%m-%d')
        # ì›ë³¸ ë¶„ì„ í…ìŠ¤íŠ¸ ë³´ì¡´ (JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        original_analysis_text = result.get('analysis', '')
        
        # structured_analysisê°€ ìˆê³  ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° analysisë¡œ ì´ë™í•˜ê³  ì¤‘ë³µ ì œê±°
        if 'structured_analysis' in result and result['structured_analysis']:
            structured = result['structured_analysis']
            # ë¹ˆ êµ¬ì¡°ê°€ ì•„ë‹Œì§€ í™•ì¸ (summaryë‚˜ participantsì— ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ”ì§€)
            has_data = (
                (structured.get('summary', {}) and 
                 (structured['summary'].get('overview') or 
                  (structured['summary'].get('topics') and len(structured['summary']['topics']) > 0) or
                  (structured['summary'].get('key_decisions') and len(structured['summary']['key_decisions']) > 0) or
                  (structured['summary'].get('major_achievements') and len(structured['summary']['major_achievements']) > 0) or
                  (structured['summary'].get('common_issues') and len(structured['summary']['common_issues']) > 0))) or
                (structured.get('participants') and len(structured['participants']) > 0)
            )
            if has_data:
                # JSON í˜•ì‹ì˜ ê²½ìš° structured_analysisë¥¼ analysisë¡œ ë³µì‚¬í•˜ê³  ì¤‘ë³µ ì œê±°
                result['analysis'] = result['structured_analysis']
                
                # participants_analysisë¥¼ participantsë¡œ ì´ë¦„ ë³€ê²½ (í•˜ìœ„ í˜¸í™˜ì„±)
                if 'participants_analysis' in result['analysis']:
                    # participants_analysisë¥¼ participantsë¡œ ì´ë¦„ ë³€ê²½
                    result['analysis']['participants'] = result['analysis'].pop('participants_analysis')
                
                # ìµœìƒìœ„ participantsì˜ speak_count, word_countë¥¼ analysis.participantsì— ë³‘í•©
                if 'participants' in result and 'analysis' in result and isinstance(result['analysis'], dict):
                    top_level_participants = result['participants']  # ìµœìƒìœ„ participants (í†µê³„ ì •ë³´ í¬í•¨)
                    analysis_participants = result['analysis'].get('participants', [])
                    
                    # ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­í•˜ì—¬ speak_count, word_count ì¶”ê°€ ë° speaking_percentage ì¬ê³„ì‚°
                    top_level_dict = {p.get('name'): p for p in top_level_participants}
                    
                    # ì „ì²´ word_count í•©ê³„ ê³„ì‚° (ë¹„ì¤‘ ê³„ì‚°ìš©) - top_level_participants ê¸°ì¤€
                    total_word_count = sum(p.get('word_count', 0) for p in top_level_participants)
                    
                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ì´ë¯¸ ì²˜ë¦¬í•œ ì°¸ì—¬ì ì´ë¦„ ì¶”ì 
                    processed_names = set()
                    unique_participants = []
                    
                    for participant in analysis_participants:
                        participant_name = participant.get('name', '')
                        
                        # ì¤‘ë³µ ì œê±°: ê°™ì€ ì´ë¦„ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìœ¼ë©´ ê±´ë„ˆëœ€
                        if participant_name in processed_names:
                            continue
                        
                        if participant_name in top_level_dict:
                            # speak_count, word_count ì¶”ê°€
                            participant['speak_count'] = top_level_dict[participant_name].get('speak_count', 0)
                            participant['word_count'] = top_level_dict[participant_name].get('word_count', 0)
                            
                            # ì‹¤ì œ ê³„ì‚°ëœ speaking_time ì‚¬ìš© (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
                            top_level_participant = top_level_dict[participant_name]
                            if 'speaking_time' in top_level_participant:
                                participant['speaking_time'] = top_level_participant['speaking_time']
                            if 'speaking_time_seconds' in top_level_participant:
                                participant['speaking_time_seconds'] = top_level_participant['speaking_time_seconds']
                            
                            # word_countë¥¼ ê¸°ë°˜ìœ¼ë¡œ speaking_percentage ì¬ê³„ì‚° (ì •í™•í•œ ë¹„ì¤‘)
                            word_count = participant['word_count']
                            if total_word_count > 0:
                                participant['speaking_percentage'] = round((word_count / total_word_count) * 100, 1)
                            else:
                                participant['speaking_percentage'] = 0.0
                            
                            processed_names.add(participant_name)
                            unique_participants.append(participant)
                    
                    # ì¤‘ë³µ ì œê±°ëœ participantsë¡œ êµì²´
                    result['analysis']['participants'] = unique_participants
                    
                    # ì‹¤ì œ ê³„ì‚°ëœ íšŒì˜ ì‹œê°„ ì‚¬ìš© (AI ìƒì„± ê°’ ëŒ€ì‹ )
                    if 'total_meeting_time' in result:
                        # summary.overview.total_timeì„ ì‹¤ì œ ê³„ì‚°ëœ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                        if 'summary' in result['analysis'] and isinstance(result['analysis']['summary'], dict):
                            if 'overview' in result['analysis']['summary']:
                                result['analysis']['summary']['overview']['total_time'] = result['total_meeting_time']
                    
                    # ìµœìƒìœ„ participants í•„ë“œ ì œê±° (ì¤‘ë³µì´ë¯€ë¡œ)
                    del result['participants']
                
                # participants_formatted í•„ë“œ ì œê±°
                if 'participants_formatted' in result:
                    del result['participants_formatted']
                
                # structured_analysisëŠ” ì¤‘ë³µì´ë¯€ë¡œ ì œê±°
                del result['structured_analysis']
            else:
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì›ë³¸ analysis_text ìœ ì§€í•˜ê³  structured_analysis ì œê±°
                result['analysis'] = original_analysis_text
                del result['structured_analysis']
        else:
            # structured_analysisê°€ ì—†ìœ¼ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€
            result['analysis'] = original_analysis_text
    
    return analyzed_results


def _generate_markdown_content(analyzed_results: list, target_date: datetime) -> str:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ìƒì„±
    
    Args:
        analyzed_results: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
        
    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¬¸ìì—´
    """
    from io import StringIO
    from datetime import datetime
    
    output = StringIO()
    analysis_time = datetime.now()
    
    output.write(f"# Daily Work Report - {target_date.strftime('%B %d, %Y')}\n\n")
    output.write(f"**Generated at**: {analysis_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
    output.write("---\n\n")
    
    for result in analyzed_results:
        output.write(f"## Meeting Information\n\n")
        output.write(f"- **Target Date**: {target_date.strftime('%Y-%m-%d')}\n")
        output.write(f"- **Number of Meetings Analyzed**: {result.get('meeting_count', len(result.get('target_meetings', [])))}\n")
        
        # target_meetings ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if 'target_meetings' in result and result['target_meetings']:
            output.write(f"\n### Analyzed Meetings List\n\n")
            for idx, target_meeting in enumerate(result['target_meetings'], 1):
                output.write(f"{idx}. **{target_meeting.get('meeting_title', 'N/A')}**\n")
                output.write(f"   - ID: `{target_meeting.get('meeting_id', 'N/A')}`\n")
                output.write(f"   - Created Time: {target_meeting.get('created_time', 'N/A')}\n")
        
        output.write("\n---\n\n")
        
        # JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
        analysis = result.get('analysis', {})
        if isinstance(analysis, dict) and 'summary' in analysis:
            # JSON í˜•ì‹ì˜ ë¶„ì„ ë°ì´í„°
            # ë¹ˆ êµ¬ì¡°ê°€ ì•„ë‹Œì§€ í™•ì¸
            has_data = (
                (analysis.get('summary', {}) and 
                 (analysis['summary'].get('overview') or 
                  (analysis['summary'].get('topics') and len(analysis['summary']['topics']) > 0) or
                  (analysis['summary'].get('key_decisions') and len(analysis['summary']['key_decisions']) > 0) or
                  (analysis['summary'].get('major_achievements') and len(analysis['summary']['major_achievements']) > 0) or
                  (analysis['summary'].get('common_issues') and len(analysis['summary']['common_issues']) > 0))) or
                (analysis.get('participants') and len(analysis['participants']) > 0)
            )
            if has_data:
                _write_json_analysis_to_markdown(output, analysis)
            else:
                # ë¹ˆ êµ¬ì¡°ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ í™•ì¸
                analysis_data = result.get('analysis', {})
                if isinstance(analysis_data, dict):
                    original_text = analysis_data.get('full_analysis_text', analysis_data.get('_raw', ''))
                else:
                    original_text = str(analysis_data) if analysis_data else ''
                if isinstance(original_text, str) and original_text:
                    output.write("## Analysis Results\n\n")
                    output.write("âš ï¸ JSON parsing succeeded but the structure is empty. Showing original response:\n\n")
                    output.write("```json\n")
                    output.write(original_text)
                    output.write("\n```\n\n")
                else:
                    output.write("âš ï¸ No analysis results available.\n\n")
        else:
            # ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë˜ëŠ” ë¬¸ìì—´
            if isinstance(analysis, dict):
                analysis_text = analysis.get('analysis', '')
            else:
                analysis_text = str(analysis)
            if analysis_text:
                output.write(analysis_text)
                output.write("\n\n")
            else:
                output.write("âš ï¸ No analysis results available.\n\n")
    
    return output.getvalue()


def save_daily_report(analyzer: MeetingPerformanceAnalyzer, analyzed_results: list, 
                     target_date: datetime,
                     output_database_name: str = "gemini", 
                     output_collection_name: str = "daily_reports"):
    """
    ì¼ê°„ ë³´ê³ ì„œë¥¼ MongoDBì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        analyzer: MeetingPerformanceAnalyzer ì¸ìŠ¤í„´ìŠ¤
        analyzed_results: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
        output_database_name: ì €ì¥í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ê¸°ë³¸ê°’: "gemini")
        output_collection_name: ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„ (ê¸°ë³¸ê°’: "daily_reports")
    """
    if not analyzed_results:
        return
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë‚´ìš© ìƒì„±
    markdown_content = _generate_markdown_content(analyzed_results, target_date)
    
    # ê° ê²°ê³¼ì— ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì„ analysis ì•ˆì— full_analysis_textë¡œ ì €ì¥
    for result in analyzed_results:
        # analysisê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        current_analysis = result.get('analysis', {})
        if not isinstance(current_analysis, dict):
            # ê¸°ì¡´ analysis ê°’ì„ ë³´ì¡´
            existing_analysis = current_analysis
            result['analysis'] = {}
            # ê¸°ì¡´ ê°’ì´ ë¬¸ìì—´ì´ë©´ ì„ì‹œë¡œ ì €ì¥
            if isinstance(existing_analysis, str):
                result['analysis']['_raw'] = existing_analysis
            # ê¸°ì¡´ ê°’ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ summaryì™€ participants êµ¬ì¡°ë¡œ ë³€í™˜
            # (JSON íŒŒì‹± ì‹¤íŒ¨í•œ ê²½ìš°)
        
        # analysis ë”•ì…”ë„ˆë¦¬ì— full_analysis_text ì¶”ê°€
        if not isinstance(result.get('analysis'), dict):
            result['analysis'] = {}
        result['analysis']['full_analysis_text'] = markdown_content
    
    # MongoDBì— ì €ì¥
    analyzer.save_analysis_to_mongodb(
        analyzed_results,
        output_collection_name=output_collection_name,
        output_database_name=output_database_name
    )
    
    print(f"âœ… ì¼ê°„ ë³´ê³ ì„œê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   Database: {output_database_name}")
    print(f"   Collection: {output_collection_name}")


def _json_analysis_to_markdown_string(analysis_data: dict) -> str:
    """
    JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´ë¡œ ë³€í™˜
    
    Args:
        analysis_data: JSON í˜•ì‹ì˜ ë¶„ì„ ë°ì´í„°
        
    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¬¸ìì—´
    """
    from io import StringIO
    
    output = StringIO()
    _write_json_analysis_to_markdown(output, analysis_data)
    return output.getvalue()


def _write_json_analysis_to_markdown(file, analysis_data: dict):
    """
    JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì¼ì— ì‘ì„±
    
    Args:
        file: íŒŒì¼ ê°ì²´
        analysis_data: JSON í˜•ì‹ì˜ ë¶„ì„ ë°ì´í„°
    """
    # Summary ì„¹ì…˜
    summary = analysis_data.get('summary', {})
    if summary:
        file.write("## Summary of Today's Meetings\n\n")
        
        # Overview
        overview = summary.get('overview', {})
        if overview:
            file.write("### Overall Meeting Overview\n\n")
            file.write(f"- Total Number of Meetings: {overview.get('meeting_count', 'N/A')}\n")
            file.write(f"- Total Meeting Time: {overview.get('total_time', 'N/A')}\n")
            main_topics = overview.get('main_topics', [])
            if main_topics:
                file.write(f"- Main Discussion Topics: {', '.join(main_topics)}\n")
            file.write("\n")
        
        # Topics
        topics = summary.get('topics', [])
        if topics:
            file.write("### Meeting Content by Topic\n\n")
            for topic in topics:
                topic_name = topic.get('topic', '')
                if topic_name:
                    file.write(f"#### {topic_name}\n\n")
                    related_meetings = topic.get('related_meetings', [])
                    if related_meetings:
                        file.write(f"- **Related Meetings**: {', '.join(related_meetings)}\n")
                    
                    key_discussions = topic.get('key_discussions', [])
                    if key_discussions:
                        file.write("- **Key Discussion Points**:\n")
                        for discussion in key_discussions:
                            file.write(f"  - {discussion}\n")
                    
                    key_decisions = topic.get('key_decisions', [])
                    if key_decisions:
                        file.write("- **Key Decisions**:\n")
                        for decision in key_decisions:
                            file.write(f"  - {decision}\n")
                    
                    progress = topic.get('progress', [])
                    if progress:
                        file.write("- **Progress**:\n")
                        for prog in progress:
                            file.write(f"  - {prog}\n")
                    
                    issues = topic.get('issues', [])
                    if issues:
                        file.write("- **Issues and Blockers**:\n")
                        for issue in issues:
                            file.write(f"  - {issue}\n")
                    
                    file.write("\n")
        
        # Key Decisions
        key_decisions = summary.get('key_decisions', [])
        if key_decisions:
            file.write("### Key Decisions (Overall Summary)\n\n")
            for decision in key_decisions:
                file.write(f"- {decision}\n")
            file.write("\n")
        
        # Major Achievements
        major_achievements = summary.get('major_achievements', [])
        if major_achievements:
            file.write("### Major Achievements and Progress (Overall Summary)\n\n")
            for achievement in major_achievements:
                file.write(f"- {achievement}\n")
            file.write("\n")
        
        # Common Issues
        common_issues = summary.get('common_issues', [])
        if common_issues:
            file.write("### Common Issues and Blockers (Overall Summary)\n\n")
            for issue in common_issues:
                file.write(f"- {issue}\n")
            file.write("\n")
        
        file.write("---\n\n")
    
    # Participants Analysis
    participants = analysis_data.get('participants', [])
    if participants:
        for participant in participants:
            name = participant.get('name', '')
            if name:
                file.write(f"## {name}\n\n")
                
                speaking_time = participant.get('speaking_time')
                speaking_percentage = participant.get('speaking_percentage')
                if speaking_time or speaking_percentage:
                    file.write("### Speaking Time\n\n")
                    if speaking_time and speaking_percentage:
                        file.write(f"- {speaking_time} ({speaking_percentage}% of total)\n")
                    elif speaking_time:
                        file.write(f"- {speaking_time}\n")
                    elif speaking_percentage:
                        file.write(f"- {speaking_percentage}% of total\n")
                    file.write("\n")
                
                key_activities = participant.get('key_activities', [])
                if key_activities:
                    file.write("### Today's Key Activities\n\n")
                    for activity in key_activities:
                        file.write(f"- {activity}\n")
                    file.write("\n")
                
                progress = participant.get('progress', [])
                if progress:
                    file.write("### Progress and Achievements\n\n")
                    for prog in progress:
                        file.write(f"- {prog}\n")
                    file.write("\n")
                
                issues = participant.get('issues', [])
                if issues:
                    file.write("### Issues and Blockers\n\n")
                    for issue in issues:
                        file.write(f"- {issue}\n")
                    file.write("\n")
                
                action_items = participant.get('action_items', [])
                if action_items:
                    file.write("### Next Action Items\n\n")
                    for item in action_items:
                        file.write(f"- [ ] {item}\n")
                    file.write("\n")
                
                collaboration = participant.get('collaboration', [])
                if collaboration:
                    file.write("### Collaboration Status\n\n")
                    for collab in collaboration:
                        file.write(f"- {collab}\n")
                    file.write("\n")
                
                file.write("---\n\n")


def save_daily_report_to_file(analyzed_results: list, target_date: datetime, output_dir: str = "output"):
    """
    ì¼ê°„ ë³´ê³ ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        analyzed_results: ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    if not analyzed_results:
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # ë¶„ì„ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
    analysis_time = datetime.now()
    analysis_time_str = analysis_time.strftime('%Y%m%d_%H%M%S')
    
    # íŒŒì¼ëª… ìƒì„± (ë‚ ì§œ + ë¶„ì„ ì‹œê°„ í¬í•¨)
    date_str = target_date.strftime('%Y%m%d')
    md_filename = os.path.join(output_dir, f"daily_report_{date_str}_{analysis_time_str}.md")
    json_filename = os.path.join(output_dir, f"daily_report_{date_str}_{analysis_time_str}.json")
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    with open(md_filename, 'w', encoding='utf-8') as f:
        f.write(f"# Daily Work Report - {target_date.strftime('%B %d, %Y')}\n\n")
        f.write(f"**Generated at**: {analysis_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("---\n\n")
        
        for result in analyzed_results:
            f.write(f"## Meeting Information\n\n")
            f.write(f"- **Target Date**: {target_date.strftime('%Y-%m-%d')}\n")
            f.write(f"- **Number of Meetings Analyzed**: {result.get('meeting_count', len(result.get('target_meetings', [])))}\n")
            
            # target_meetings ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if 'target_meetings' in result and result['target_meetings']:
                f.write(f"\n### Analyzed Meetings List\n\n")
                for idx, target_meeting in enumerate(result['target_meetings'], 1):
                    f.write(f"{idx}. **{target_meeting.get('meeting_title', 'N/A')}**\n")
                    f.write(f"   - ID: `{target_meeting.get('meeting_id', 'N/A')}`\n")
                    f.write(f"   - Created Time: {target_meeting.get('created_time', 'N/A')}\n")
            
            f.write("\n---\n\n")
            
            # JSON í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
            analysis = result.get('analysis', {})
            if isinstance(analysis, dict) and 'summary' in analysis:
                # JSON í˜•ì‹ì˜ ë¶„ì„ ë°ì´í„°
                # ë¹ˆ êµ¬ì¡°ê°€ ì•„ë‹Œì§€ í™•ì¸
                has_data = (
                    (analysis.get('summary', {}) and 
                     (analysis['summary'].get('overview') or 
                      (analysis['summary'].get('topics') and len(analysis['summary']['topics']) > 0) or
                      (analysis['summary'].get('key_decisions') and len(analysis['summary']['key_decisions']) > 0) or
                      (analysis['summary'].get('major_achievements') and len(analysis['summary']['major_achievements']) > 0) or
                      (analysis['summary'].get('common_issues') and len(analysis['summary']['common_issues']) > 0))) or
                    (analysis.get('participants') and len(analysis['participants']) > 0)
                )
                if has_data:
                    _write_json_analysis_to_markdown(f, analysis)
                else:
                    # ë¹ˆ êµ¬ì¡°ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ í™•ì¸
                    original_text = result.get('analysis', '')
                    if isinstance(original_text, str) and original_text:
                        f.write("## Analysis Results\n\n")
                        f.write("âš ï¸ JSON parsing succeeded but the structure is empty. Showing original response:\n\n")
                        f.write("```json\n")
                        f.write(original_text)
                        f.write("\n```\n\n")
                    else:
                        f.write("âš ï¸ No analysis results available.\n\n")
            else:
                # ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë˜ëŠ” ë¬¸ìì—´
                if isinstance(analysis, dict):
                    analysis_text = analysis.get('analysis', '')
                else:
                    analysis_text = str(analysis)
                if analysis_text:
                    f.write(analysis_text)
                    f.write("\n\n")
                else:
                    f.write("âš ï¸ No analysis results available.\n\n")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(analyzed_results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"ğŸ’¾ ì¼ê°„ ë³´ê³ ì„œ íŒŒì¼ ì €ì¥ ì™„ë£Œ:")
    print(f"   - {md_filename}")
    print(f"   - {json_filename}")


def main(date_str: str = None):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        date_str: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹). Noneì´ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
    """
    print("\n" + "=" * 70)
    print("ğŸ“… ì¼ê°„ ì—…ë¬´ ë³´ê³ ì„œ ìƒì„±ê¸°")
    print("=" * 70)
    
    # ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ ê²°ì •
    target_date = get_target_date(date_str)
    print(f"\nğŸ“† ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ: {target_date.strftime('%Y-%m-%d')}")
    
    try:
        # Analyzer ìƒì„± (daily_report í…œí”Œë¦¿ ì‚¬ìš©)
        analyzer = get_analyzer(
            prompt_template="daily_report",
            template_version="latest"  # ìµœì‹  ë²„ì „ ì‚¬ìš©
        )
        
        # í•´ë‹¹ ë‚ ì§œì˜ íšŒì˜ë“¤ ê°€ì ¸ì˜¤ê¸°
        meetings = fetch_meetings_for_date(analyzer, target_date)
        
        if not meetings:
            print(f"âš ï¸  {target_date.strftime('%Y-%m-%d')} ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” íšŒì˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… {len(meetings)}ê°œì˜ íšŒì˜ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # íšŒì˜ ì œëª© ì¶œë ¥
        print("\nğŸ“‹ ë¶„ì„ ëŒ€ìƒ íšŒì˜:")
        for i, meeting in enumerate(meetings, 1):
            meeting_title = meeting.get('title', meeting.get('name', 'N/A'))
            meeting_date = meeting.get('date', meeting.get('createdTime', 'N/A'))
            print(f"   {i}. {meeting_title} ({meeting_date})")
        
        # ì¼ê°„ ë³´ê³ ì„œ ìƒì„±
        analyzed_results = generate_daily_report(analyzer, meetings, target_date)
        
        if not analyzed_results:
            print("âš ï¸  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # MongoDBì— ì €ì¥
        save_daily_report(analyzer, analyzed_results, target_date, output_database_name="test_database", output_collection_name="daily_reports")
        
        # íŒŒì¼ë¡œ ì €ì¥
        save_daily_report_to_file(analyzed_results, target_date)
        
        print("\nâœ… ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ì—°ê²° ì¢…ë£Œ
        if 'analyzer' in locals():
            analyzer.close()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ì¼ê°„ ì—…ë¬´ ë³´ê³ ì„œ ìƒì„±')
    parser.add_argument(
        '--date',
        type=str,
        help='ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹). ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©',
        default=None
    )
    
    args = parser.parse_args()
    main(args.date)

